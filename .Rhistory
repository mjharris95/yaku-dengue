<<<<<<< Updated upstream
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "95",
pctile > .90 ~ "90",
pctile > .85 ~ "85",
pctile <= .85 ~ "Non-extreme"
)) -> clim_df
clim-df
clim_df
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "95",
pctile > .90 ~ "90",
pctile > .85 ~ "85",
pctile <= .85 ~ "Non-extreme"
)) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))
clim_df
per_map
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< .85)"
)) %>%
rename(id = DEPARTAMEN) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< .85)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< .85)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
void()
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< .85)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
theme_void()
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_discrete("Percentile")+
theme_void()+
theme(legend.position="bottom")
?scale_fill_discrete
?scale_fill_manual
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"))+
theme_void()+
theme(legend.position="bottom")
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"+
)
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th")+
theme_void()+
theme(legend.position="bottom")
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th")+
theme_void()+
theme(legend.position="bottom")
breaks=rev(c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom")
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09").
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom")
# read in peru map
per_map <- read_sf("maps/CDC_Departamentos.shp")
# Plot percentile anomaly in March
# read in precipitation
fread("march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom")
library(data.table)
library(tidyverse)
library(sf)
# read in peru map
per_map <- read_sf("maps/CDC_Departamentos.shp")
files <- dir("D:/Attribution/march-clim_df.csv")
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom")
ggsave("figs/pctile-anomaly.pdf", height=8, width=8, units="in")
ggsave("figs/pctile-anomaly.pdf", height=4, width=4, units="in")
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom", legend.box="vertical")
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom")+
guides(fill=guide_legend(nrow=2,byrow=TRUE))
ggsave("figs/pctile-anomaly.pdf", height=4, width=4, units="in")
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom")+
guides(fill=guide_legend(nrow=2,byrow=FALSE))
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()+
theme(legend.position="bottom")+
guides(fill=guide_legend(nrow=4,byrow=FALSE))
# read in precipitation
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>%
# take March mean
group_by(id, year) %>%
summarize(mean_rain = mean(rain)) %>%
# calculate percentiles
group_by(id) %>%
mutate(pctile = percent_rank(mean_rain)) %>%
filter(year == 2023) %>%
mutate(pctile_dis = case_when(
pctile > .95 ~ "> 95th",
pctile > .90 ~ "> 90th",
pctile > .85 ~ "> 85th",
pctile <= .85 ~ "Non-extreme (< 85th)"
)) %>%
rename(DEPARTAMEN = id) %>%
# append to Peru map
merge(per_map, .) %>%
# plot
ggplot() +
geom_sf(aes(fill=pctile_dis))+
scale_fill_manual("Percentile",
values=c("white", "#ffa590", "#ff4122", "#c61a09"),
breaks=c("Non-extreme (< 85th)", "> 85th", "> 90th", "> 95th"))+
theme_void()
ggsave("figs/pctile-anomaly.pdf", height=4, width=4, units="in")
clim_df$year %>% min()
fread("march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>% select(year) %>% min()
fread("D:/Attribution/march-clim_df.csv") %>%
# filter to Peru at admin1
filter(country=="PER") %>%
# get year
mutate(year = year(date)) %>% select(year) %>% min()
=======
if(length(cases_2023)==0){
cases_2023_set <- unique(clim_df$id)
} else{
cases_2023_set <- cases_2023
}
clim_df %<>%
# focus on coastal peruvian districts with data
filter(country %in% my_country) %>%
filter(!is.na(rain)) %>%
filter(id %in% coastal_dist_set) %>%
filter(id %in% cases_2023_set) %>%
filter(id %in% c(extreme_ids, nonextreme_ids)) %>%
# indicate post_cyclone observations
mutate(date = as_date(date)) %>%
mutate(int = ifelse(date >= as_date("2023-03-07") & id %in% extreme_ids, 1, 0)) %>%
mutate(week = epiweek(date), year = year(date)) %>%
filter(year >= 2018)
# define 4-week periods ("steps")
step_help <- clim_df %>%
group_by(week, year) %>%
summarize(date_end = max(date)) %>%
ungroup() %>%
arrange(date_end) %>%
mutate(weeknum = row_number()) %>%
mutate(step = ceiling(weeknum/4)) %>%
mutate(step = as.integer(step))
years <- unique(step_help$year)
year_ind <- sapply(unique(step_help$year), function(x) min(which(step_help$year==x))/4)
# note: I think this need to be fixed
step_filter <- step_help %>%
group_by(step) %>%
summarize(frq = n()) %>%
filter(frq < 4) %>%
select(step) %>%
unlist()
clim_df %<>% left_join(step_help) %>%
filter(! step %in% step_filter) %>%
group_by(id, country, step) %>%
summarize(mean_rel_r0 = mean(rel_r0),
mean_rain = mean(rain),
mean_temp = mean(temp),
int = max(int),
date_end = max(date)) %>%
mutate(mean_rain = mean_rain * 1000) %>%
# format for matching package
transform(place = as.integer(as.factor(id))) %>%
mutate(is_control = ifelse(id %in% extreme_ids, "Treated", "Untreated"))
# how many steps to match on
lag_num <- nrow(filter(clim_df, is_control == "Treated" & int==0) %>%
select(step) %>%
distinct())
unmatch_res <- PanelMatch(lag = lag_num, time.id = "step", unit.id = "place",
treatment = "int", refinement.method = "none",
data = clim_df, match.missing =FALSE,
size.match = match_num, qoi = "att",
use.diagonal.variance.matrix = TRUE,
covs.formula = ~ mean_temp + mean_rain,
outcome.var = "mean_rain")
# conduct matching for each of the treated provinces
match_res <- PanelMatch(lag = lag_num, time.id = "step", unit.id = "place",
treatment = "int", refinement.method = "mahalanobis",
data = clim_df, match.missing =FALSE,
size.match = match_num, qoi = "att",
use.diagonal.variance.matrix = TRUE,
covs.formula = ~ mean_temp + mean_rain,
outcome.var = "mean_rain")
bal_calc <- get_covariate_balance(match_res$att, clim_df, c("mean_rain", "mean_temp"), plot=FALSE) %>% colMeans()
abs_bal_calc <- get_covariate_balance(match_res$att, clim_df, c("mean_rain", "mean_temp"), plot=FALSE) %>% abs() %>% colMeans()
matched_prov <- list()
for(i in 1:length(match_res$att)){
matched_prov[[i]] <- names(attr(match_res$att[[i]], "weights")[attr(match_res$att[[i]], "weights") != 0])
}
match_df <- matched_prov %>%
unlist() %>%
as.numeric() %>%
data.frame(place = .) %>%
group_by(place) %>%
summarize(weight=n()) %>%
right_join(clim_df) %>%
mutate(weight = ifelse(is.na(weight), 1, weight))
matched_names <- match_df %>% filter(place %in% unlist(matched_prov)) %>% select(id) %>% unlist() %>% unique()
match_df %<>% mutate(is_control = ifelse(id %in% matched_names, "Matched Control", is_control))
match_tab <-   match_df %>%
filter(is_control == "Matched Control") %>%
mutate(is_control = "Untreated",
weight = 1) %>%
rbind(match_df) %>%
group_by(is_control) %>%
summarize(Temperature = weighted.mean(mean_temp, weight),
Rainfall = weighted.mean(mean_rain, weight),
n = length(unique(id)))
treated_names <- filter(match_df, is_control == "Treated") %>%
select(id) %>%
unlist() %>%
unique()
match_out <- list("table" = match_tab,
"match_names" = matched_names,
"df" = match_df,
"treated_names" = treated_names,
"match_obj" = match_res,
"balance" = bal_calc,
"abs_bal" = abs_bal_calc,
"match_list" = matched_prov)
if(plot_bal == TRUE){
balance_plot(unmatch_res, match_res, clim_df, lag_num, file_prefix, years, year_ind)
balance_plot2(match_out, lag_num, file_prefix, years, year_ind)
climts_plot(match_df, lag_num, file_prefix, years, year_ind)
}
if(plot_map == TRUE){
matchmap_plot(map, big_map, file_prefix, match_df,
cases_2023 = cases_2023, coastal_dist = coastal_dist)
}
return(match_out)
}
synth_fun <- function(case_df, match_out, file_prefix,
att_plot = FALSE,
spatt_plot = FALSE, map = NULL,
big_map = NULL,
lf_num=NA, r.max=5, use_clim=FALSE,
inc=FALSE, start_year = 2010,
end_week = 52, log_cases=FALSE,
give_group = c(), method="ife") {
if(spatt_plot==TRUE & is.null(map)){
stop("Provide map to plot")
}
incl_units <- c(match_out$treated_names, match_out$match_names)
if(use_clim == TRUE){
# read in climate
df <- fread("D:/Attribution/clim_df.csv") %>%
# filter to treated and matched control regions
filter(id %in% incl_units) %>%
filter(date <= as_date("2023-12-31")) %>%
# convert to epiweek
mutate(week=epiweek(date), year=year(date), month=month(date))  %>%
# sometimes the last few days of a year get assigned to first epiweek of following year
mutate(year = ifelse(week == 1 & month == 12, year+1, year)) %>%
group_by(week, year, id) %>%
summarize(mean_temp = mean(temp),
mean_rain = mean(rain),
mean_rel_r0 = mean(rel_r0)) %>%
left_join(case_df) %>%
filter(!is.na(mean_temp)) %>%
filter(id %in% incl_units) %>%
filter(year >= start_year) %>%
filter(week <= end_week) %>%
filter(year <= 2023)
} else{
df <- case_df %>%
filter(id %in% incl_units) %>%
mutate(mean_temp = NA, mean_rain = NA, mean_rel_r0 = NA) %>%
filter(year >= start_year)
}
time_df <- df %>%
mutate(time = week+(year-min(case_df$year))*100) %>%
select(time, week, year) %>%
distinct() %>%
arrange(time) %>%
ungroup() %>%
mutate(weeknum = row_number()) %>%
mutate(step = ceiling(weeknum/4)) %>%
mutate(step = as.integer(step))
# will use this in plotting later
year_ind <- sapply(unique(time_df$year), function(x) min(which(time_df$year==x))/4)
years <- unique(time_df$year)
# aggregate to 4-epiweek periods
df <- time_df %>%
right_join(df) %>%
group_by(id, step) %>%
summarize(cases = sum(cases),
inc = sum(inc),
mean_temp = mean(mean_temp),
mean_rel_r0 = mean(mean_rel_r0),
mean_rain = mean(mean_rain)*1000,
pop = mean(pop))
# when did the cyclone happen?
cyclone_step <- unique(time_df$step[time_df$week == 10 & time_df$year==2023])
# input a zero in weeks with missing data
df <- expand.grid(step=1:max(df$step), id=incl_units) %>%
left_join(df) %>%
mutate(cases = ifelse(is.na(cases), 0, cases),
inc = ifelse(is.na(inc), 0, inc)) %>%
mutate(int = ifelse(id %in% match_out$treated_names & step >= cyclone_step, 1, 0)) %>%
mutate(log_cases = log(cases+1)) %>%
left_join(., match_out$df %>% select(id, is_control) %>% distinct() %>% filter(is_control %in% c("Treated", "Matched Control")))
if(inc == TRUE){
df %<>% mutate(y = inc)
}
else if(log_cases == TRUE){
df %<>% mutate(y = log_cases)
}
else{
df %<>% mutate(y = cases)
}
if(is.na(lf_num)){
CV <- TRUE
r <- c(0,r.max)
}
else{
CV <- FALSE
r <- lf_num
}
if(length(give_group)==0){
df$group <- df$id
}
else{
df$group <- ifelse(df$id %in% give_group, "1", "0")
}
if(use_clim == TRUE){
gsynth_out <- df %>%
fect(y ~ int + mean_rel_r0 + mean_rain, data = .,
index=c("id", "step"),
force = "two-way",
method=method,
se = TRUE,
CV = CV, r = r,
seed = 514,
nboots = 1000,
group="group")
} else {
gsynth_out <- df %>%
fect(y ~ int, data = .,
index=c("id", "step"),
force = "two-way",
method=method,
se = TRUE,
CV = CV, r = r,
seed = 514,
nboots=1000,
group="group")
}
# calculate percent attributable cases based on bootstraps
# lapply(gsynth_out$Y.boot, function(x) rowSums(x[,gsynth_out$tr])) %>%
#   do.call(cbind, .) %>%
#   `/`(gsynth_out$att.boot * length(gsynth_out$tr), .) %>%
#   apply(1, function(x) quantile(x, c(.05, .95))) %>%
#   t() %>%
#   data.frame() %>%
#   rename(lower.pct = 1,
#          upper.pct = 2) %>%
#   cbind(obs = gsynth_out$Y.dat[,gsynth_out$tr] %>% rowSums()) %>%
#   mutate(lower.num = lower.pct*obs,
#          upper.num=upper.pct*obs)
if(att_plot==TRUE){
att_plot(df, gsynth_out, cyclone_step, file_prefix,
year_ind, unique(time_df$year), inc = inc)
}
if(spatt_plot==TRUE){
spatt_plot(case_df, gsynth_out,
map = map, big_map = big_map, file_prefix=file_prefix,
inc=inc)
}
att_nums <- att_print(gsynth_out, df, cyclone_step,
pop_df, inc = inc)
return(list("gsynth_obj"=gsynth_out,
"att_nums"=att_nums,
"year_ind"=year_ind,
"years"=years))
}
synth_out_allper <- synth_fun(case_df, match_out_allper, "adm3-allper",
att_plot=FALSE, spatt_plot=FALSE, map=per_map, big_map=dept_map, use_clim=TRUE,
start_year = 2016)
gsynth_obj<-synth_out_allper$gsynth_obj
# calculate percent attributable cases based on bootstraps
lapply(gsynth_out$Y.boot, function(x) rowSums(x[,gsynth_out$tr])) %>%
do.call(cbind, .) %>%
`/`(gsynth_out$att.boot * length(gsynth_out$tr), .) %>%
apply(1, function(x) quantile(x, c(.05, .95))) %>%
t() %>%
data.frame() %>%
rename(lower.pct = 1,
upper.pct = 2) %>%
cbind(obs = gsynth_out$Y.dat[,gsynth_out$tr] %>% rowSums()) %>%
mutate(lower.num = lower.pct*obs,
upper.num=upper.pct*obs)
`/`(1*8, 8)
`/`(8*10, 8)
gsynth_out$Y.boot[[1]]
gsynth_out$Y.boot[[1]] %>% dim()
# calculate percent attributable cases based on bootstraps
lapply(gsynth_out$Y.boot, function(x) rowSums(x[,1:length(gsynth_out$tr)])) %>%
do.call(cbind, .) %>%
`/`(gsynth_out$att.boot * length(gsynth_out$tr), .) %>%
apply(1, function(x) quantile(x, c(.05, .95))) %>%
t() %>%
data.frame() %>%
rename(lower.pct = 1,
upper.pct = 2) %>%
cbind(obs = gsynth_out$Y.dat[,gsynth_out$tr] %>% rowSums()) %>%
mutate(lower.num = lower.pct*obs,
upper.num=upper.pct*obs)
match_back <- function(x){
which(apply(gsynth_out$Y.dat,2,function(m) m==y)==56)
}
match_back(gsynth_out$Y.boot[[1]][,1])
match_back <- function(x){
which(apply(gsynth_out$Y.dat,2,function(m) m==x)==56)
}
match_back(gsynth_out$Y.boot[[1]][,1])
gsynth_out$Y.dat[.1]
gsynth_out$Y.dat[,1]
gsynth_out$Y.dat[,1] %>% length()
match_back <- function(x){
which(apply(gsynth_out$Y.dat,2,function(m) m==x)==104))
match_back <- function(x){
which(apply(gsynth_out$Y.dat,2,function(m) m==x)==104)}
match_back(gsynth_out$Y.boot[[1]][,1])
match_back <- function(x){
which(apply(gsynth_out$Y.dat,2,function(m) sum(m==x))==104)}
match_back(gsynth_out$Y.boot[[1]][,1])
match_back(gsynth_out$Y.boot[[1]][,1]) %in% gsynth_out$tr
for(i in 1:56){
if(!match_back(gsynth_out$Y.boot[[1]][,i]) %in% gsynth_out$tr){
print("whoops")
}
}
match_back(gsynth_out$Y.boot[[1]][,1]) %in% gsynth_out$tr
match_back(gsynth_out$Y.boot[[1]][,2]) %in% gsynth_out$tr
for(i in 1:56){
if(!sum(match_back(gsynth_out$Y.boot[[1]][,i]) %in% gsynth_out$tr)){
print("whoops")
}
}
for(i in 57:273){
if(sum(!match_back(gsynth_out$Y.boot[[1]][,i]) %in% gsynth_out$tr)<1){
print("whoops")
}
}
synth_out_allper
synth_out_allper$gsynth_obj$est.att
knitr::opts_chunk$set(eval=FALSE, echo=FALSE)
#evtools::install("C:/Users/mallj/GitHub/yaku-dengue/fect-edit")
library(tidyverse)
library(sf)
library(lubridate)
library(viridis)
library(cowplot)
library(data.table)
library(PanelMatch)
library(readxl)
library(gsynth)
library(ggplotify)
library(magrittr)
library(fect)
library(beepr)
library(xtable)
library(colorspace)
source("new-plots.R")
set.seed(0514)
# select districts with cases in 2023
case_df<-readRDS("PER_adm3_cases.RDS")
cases_2023<-case_df %>%
filter(year==2023) %>%
select(ubigeo) %>%
unlist() %>%
unique()
# read in departments and select coastal ones
coastal_dept <- c("TUMBES", "PIURA", "LAMBAYEQUE",
"CAJAMARCA", "LA LIBERTAD", "ANCASH",
"CALLAO", "LIMA",
"ICA", "AREQUIPA", "MOQUEGUA", "TACNA")
coastal_dist <- read_xlsx("maps/UBIGEODISTRITOS.XLSX") %>%
filter(NOMBDEP %in% coastal_dept) %>%
select(IDDIST) %>%
mutate(IDDIST = str_pad(IDDIST, 6, pad="0")) %>%
unlist()
# read in shapefiles
per_map<-read_sf("maps/CDC_Distritos.shp") %>%
rename(id = ubigeo)
dept_map <- read_sf("maps/CDC_Departamentos.shp")
case_df <- readRDS("PER_adm3_cases.RDS") %>%
filter(year <= 2023) %>%
rename(id = ubigeo)
pop_df <- read.csv("pop/PER3_pop.csv") %>%
rename(pop = sum,
id = ubigeo) %>%
mutate(id = str_pad(id, 6, pad="0"))
case_df %<>% left_join(pop_df) %>%
mutate(inc = cases / pop)
load("D:/Attribution/peru-main.RData")
synth_out_allper <- synth_fun(case_df, match_out_allper, "adm3-allper",
att_plot=TRUE, spatt_plot=FALSE, map=per_map, big_map=dept_map, use_clim=TRUE,
start_year = 2016)
18285/49528
41022/49528
knitr::opts_chunk$set(eval=FALSE, echo=FALSE)
#evtools::install("C:/Users/mallj/GitHub/yaku-dengue/fect-edit")
library(tidyverse)
library(sf)
library(lubridate)
library(viridis)
library(cowplot)
library(data.table)
library(PanelMatch)
library(readxl)
library(gsynth)
library(ggplotify)
library(magrittr)
library(fect)
library(beepr)
library(xtable)
library(colorspace)
source("new-plots.R")
set.seed(0514)
# select districts with cases in 2023
case_df<-readRDS("PER_adm3_cases.RDS")
cases_2023<-case_df %>%
filter(year==2023) %>%
select(ubigeo) %>%
unlist() %>%
unique()
# read in departments and select coastal ones
coastal_dept <- c("TUMBES", "PIURA", "LAMBAYEQUE",
"CAJAMARCA", "LA LIBERTAD", "ANCASH",
"CALLAO", "LIMA",
"ICA", "AREQUIPA", "MOQUEGUA", "TACNA")
coastal_dist <- read_xlsx("maps/UBIGEODISTRITOS.XLSX") %>%
filter(NOMBDEP %in% coastal_dept) %>%
select(IDDIST) %>%
mutate(IDDIST = str_pad(IDDIST, 6, pad="0")) %>%
unlist()
# read in shapefiles
per_map<-read_sf("maps/CDC_Distritos.shp") %>%
rename(id = ubigeo)
dept_map <- read_sf("maps/CDC_Departamentos.shp")
case_df <- readRDS("PER_adm3_cases.RDS") %>%
filter(year <= 2023) %>%
rename(id = ubigeo)
pop_df <- read.csv("pop/PER3_pop.csv") %>%
rename(pop = sum,
id = ubigeo) %>%
mutate(id = str_pad(id, 6, pad="0"))
case_df %<>% left_join(pop_df) %>%
mutate(inc = cases / pop)
load("D:/Attribution/peru-main.RData")
load("D:/Attribution/peru-main.RData")
load("D:/Attribution/peru-main.RData")
synth_out_allper_pre16 <- synth_fun(case_df, match_out_allper, "adm3-allper-pre16",
use_clim=TRUE,
att_plot=TRUE)
synth_out_allper_pre16$gsynth_obj$est.att
synth_out_allper_pre16$gsynth_obj$est.att %>% tail(11)
synth_out_allper_pre16$gsynth_obj$est.att %>% tail(11) %>% select(mid.num, lower.num, upper.num, recalc.p, obs)
synth_out_allper_pre16$gsynth_obj$est.att %>% tail(11) %>% select(mid.num, lower.num, upper.num, recalc.p, obs) %>% filter(recalc.p < .05)
synth_out_allper_pre16$gsynth_obj$est.att %>% tail(11) %>% select(mid.num, lower.num, upper.num, recalc.p, obs) %>% filter(recalc.p < .05) %>% colSums()
c(40349, 19983, 52962)/63686
c(19735/49274)/58193
c(19735,49274)/58193
knitr::opts_chunk$set(eval=FALSE, echo=FALSE)
#evtools::install("C:/Users/mallj/GitHub/yaku-dengue/fect-edit")
library(tidyverse)
library(sf)
library(lubridate)
library(viridis)
library(cowplot)
library(data.table)
library(PanelMatch)
library(readxl)
library(gsynth)
library(ggplotify)
library(magrittr)
library(fect)
library(beepr)
library(xtable)
library(colorspace)
source("new-plots.R")
# run through cross-validation procedure to get number of latent factors (2)
load("D:/Attribution/peru-main.RData")
match_out_allper$table
synth_out_allper$gsynth_obj$beta
synth_out_allper$gsynth_obj$beta.boot
synth_out_allper$gsynth_obj$est.beta
read.csv("D:/Attribution/anomaly_df.csv")
read.csv("D:/Attribution/anomaly_df.csv")->anomaly_df
anomaly_df %>% filter(country %in% c("PER3", "PER")) %>%
mutate(adm = ifelse(country=="PER3", "A. District", "B. Region")) %>%
ggplot()+
geom_histogram(aes(x=diff_rain*1000))+
xlab("Precipitation Anomaly")+
facet_wrap(~adm, scale="free_y")+
theme_classic()#+
ggsave("figs/anomaly_dist.pdf", height=4, width=8, units="in")
read.csv("AedesR0Out.csv") -> r0_df
setwd("C:/Users/mallj/Documents/yaku-dengue")
read.csv("AedesR0Out.csv") -> r0_df
r0_df$temperature==24
r0_df$aegypti.R0.median[r0_df$temperature==24]
round(r0_df$aegypti.R0.median)==.4
r0_df$temperature[round(r0_df$aegypti.R0.median)==.4]
r0_df$temperature[round(r0_df$aegypti.R0.median, digits=1)==.4]
library(tidyverse)
library(ggplot)
plot(r0_df$temperature, r0_df$aegypti.R0.median)
plot(r0_df$temperature, r0_df$aegypti.R0.median, type="l")
plot(r0_df$temperature, r0_df$aegypti.R0.median, type="l", xlab="Relative R0", ylab="Temperature (C)")
abline(yintercept=.4, color="red")
vline(yintercept=.4, color="red")
vline(h=.4, color="red")
abline(h=.4, color="red")
abline(h=.4, co="red")
plot(r0_df$temperature, r0_df$aegypti.R0.median, type="l", xlab="Relative R0", ylab="Temperature (C)")
abline(h=.4, co="red")
abline(h=.4, col="red")
plot(r0_df$temperature, r0_df$aegypti.R0.median, type="l", xlab="Relative R0", ylab="Temperature (C)")
abline(v=24, col="red", type="dashed")
abline(v=24, col="red", lty="dashed")
abline(v=33, col="red", lty="dashed")
plot(r0_df$temperature, r0_df$aegypti.R0.median, type="l", xlab="Relative R0", ylab="Temperature (C)")
abline(v=33, col="red", lty="dashed")
abline(v=24, col="red", lty="dashed")
plot(r0_df$temperature, r0_df$aegypti.R0.median, type="l", ylab="Relative R0", xlab="Temperature (C)")
abline(v=24, col="red", lty="dashed")
abline(v=33, col="red", lty="dashed")
>>>>>>> Stashed changes
