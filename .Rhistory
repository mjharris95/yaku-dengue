select(id, departamento)
# regions that include at least one treated district, ordered to correspond with geographic position when faceted
dept_name$departamento <- factor(dept_name$departamento, levels=c("TUMBES", "CAJAMARCA", "PIURA", "SAN MARTIN", "LAMBAYEQUE", "LA LIBERTAD"))
spatt_scatter <- spatt_df %>%
left_join(epiweek_df) %>%
select(-step) %>%
pivot_longer(!dates, # pivot so we can plot each district as its own line
names_to = "id",
values_to = "TE")  %>%
left_join(dept_name) %>%
mutate(TE_pc = TE * 1000) %>% # calculate attributable cases per thousand people
ggplot(aes(y=TE_pc, x=dates, group=id)) +
geom_line(linewidth=.2, alpha=.5)+
theme_classic()+
facet_wrap(~departamento, ncol=2, scales="free")+ # gives axes to all plots
ylab("Attributable Cases (per Thousand)")+
xlab("Time")+
theme(legend.position="none")+
scale_x_date(date_breaks = "2 months", date_labels = "%b")+ # make the x-axis (time) nice
geom_hline(yintercept=0, color="maroon", linetype="dashed")+ # indicate zero attributable cases
scale_y_continuous(limits=c(-10, 50)) # may need to change this if not plotting main analysis
plot_grid(spatt_scatter)
ggsave(paste0("figs/", file_prefix, "-spatt-scatter.pdf"), height=6, width=8, units="in", dpi=700)
plot_grid(spatt_map, spatt_scatter, ncol = 2, labels="AUTO") # combine both plots into a grid
ggsave(paste0("figs/", file_prefix, "-spatt-map.png"), height=6, width=8, units="in", dpi=700)
}
#### MATCHING FUNCTION ####
# Matches extreme precip districts to non-extreme precip districts with most similar climate conditions
# and generates tables and (optional) plots related to this process
#
# Inputs: anomaly_upper: upper threshold for precipitation anomaly (above this considered extreme)
#         anomaly_lower: lower threshold for precipitation anomaly (below this considered non-extreme)
#                         anomaly lower must be less or equal to anomaly upper
#         coastal_dist:  optional, vector of coastal units if analysis should only be conducted on them
#         cases_2023:   optional, vector of units that reported cases in 2023 (other units excluded)
#         my_country:   countries to include in analysis. PER3 is Peru at admin level 3 (district)
#                       use this for region-level analysis: c("PER", "COL1", "ECU1", "MEX", "BRA1") - removed
#         match_num: how many non-extreme units each extreme precip district should be matched to
#         plot_bal: TRUE/FALSE, whether to plot standardized difference and mean values over time for climate covariates (to visualize balance
#         plot_map: TRUE/FALSE, whether to plot map of which units were extreme precip, non-extreme precip, matched control, excluded
#         file_prefix: prefix to save pdf image (if plot_bal or plot_map is true)
#         map: shapefile of spatial units at level used for analysis (if plot_map is true)
#         big_map: shapefile of spatial units at higher administrative division to indicate borders (if plot_map is true)
#         treated_names: leave empty to use the default defined by anomaly_upper, otherwise override and set your own treated districts
# Output: a pdf figures in the figs folder if requested and a list with the following entries
#         table: a table describing mean values across non-extreme precip, extreme precip, and control groups
#         match_names: names of the units included in matched control pool
#         df: climate covariates over time and designation (extreme precip, non-extreme precip, control) for each district
#         treated_names: names of treated units
#         match_obj: output of the PanelMatch package
#         balance: output of get_covariate_balance, gives standardized difference over time with respect to climate covariates
#         abs_bal: output of get_covariate balance, gives absolute standardized difference over time with respect to climate covariates
#         match_list: a list of length treated_names where each entry is the units matched to a given treated units
#         years: the years over which climate data is provided
#         year_ind: the indices for when a new year starts
#         cyclone_step: the index when the cyclone occured
match_fun <- function(anomaly_upper = .0085, anomaly_lower = .007,
coastal_dist = c(), cases_2023 = c(),
my_country = "PER3",
match_num = 10,
plot_bal=FALSE, plot_map=FALSE, file_prefix=NA,
map=NULL, big_map=NULL,
treated_names=c()){
# Return error if file prefix/maps are needed but not provided
if((plot_bal==TRUE | plot_map==TRUE) & is.na(file_prefix)){
stop("File prefix required to plot")
}
if((plot_map==TRUE) & (is.null(map) | is.null(big_map))){
stop("Provide map to plot")
}
# identify extreme precip, non-extreme precip, and buffer units in Peru based on upper/lower anomaly threshold
anomaly_df <- read.csv("anomaly_df.csv")
anomaly_df %>% filter(diff_rain>anomaly_upper & country %in% c("PER3", "PER")) %>% select(id) %>% unique() %>% unlist() -> extreme_ids
anomaly_df %>% filter(diff_rain<=anomaly_lower) %>% select(id) %>% unique() %>% unlist() -> nonextreme_ids
anomaly_df %>% filter(diff_rain<anomaly_upper & diff_rain>=anomaly_lower) %>% select(id) %>% unique() %>% unlist() -> buffer_ids
# override extreme precip districts if manually provided
if(length(treated_names)>0){
extreme_ids <- treated_names
}
# read in climate dataframe for matching
clim_df <- read.csv("clim_df.csv")
# if coastal_dist and cases_2023 aren't specified, choose everywhere
if(length(coastal_dist)==0){
coastal_dist_set <- unique(clim_df$id)
} else{
coastal_dist_set <- coastal_dist
}
if(length(cases_2023)==0){
cases_2023_set <- unique(clim_df$id)
} else{
cases_2023_set <- cases_2023
}
clim_df %<>%
# focus on the requested spatial units
filter(country %in% my_country) %>%
filter(!is.na(rain)) %>%
filter(id %in% coastal_dist_set) %>%
filter(id %in% cases_2023_set) %>%
filter(id %in% c(extreme_ids, nonextreme_ids)) %>%
# indicate post_cyclone observations
mutate(date = as_date(date)) %>%
mutate(int = ifelse(date >= as_date("2023-03-07") & id %in% extreme_ids, 1, 0)) %>%
mutate(week = epiweek(date), year = year(date)) %>%
filter(year >= 2018) # match from 2018 onward
# define 4-week periods ("steps")
step_help <- clim_df %>%
group_by(week, year) %>%
dplyr::summarize(date_end = max(date)) %>%
ungroup() %>%
arrange(date_end) %>%
mutate(weeknum = row_number()) %>%
mutate(step = ceiling(weeknum/4)) %>%
mutate(step = as.integer(step))
# this will help with plotting - identify steps when new years begin
years <- unique(step_help$year)
year_ind <- sapply(unique(step_help$year), function(x) min(which(step_help$year==x))/4)
# will use this to filter out if there's a step with fewer than four weeks
step_filter <- step_help %>%
group_by(step) %>%
dplyr::summarize(frq = n()) %>%
filter(frq < 4) %>%
select(step) %>%
unlist()
# take averages across four-week periods
clim_df %<>% left_join(step_help) %>%
filter(! step %in% step_filter) %>%
group_by(id, country, step) %>%
dplyr::summarize(mean_rel_r0 = mean(rel_r0),
mean_rain = mean(rain),
mean_temp = mean(temp),
int = max(int),
date_end = max(date)) %>%
mutate(mean_rain = mean_rain * 1000) %>%
# format for matching package
transform(place = as.integer(as.factor(id))) %>%
mutate(is_control = ifelse(id %in% extreme_ids, "Extreme Precipitation", "Non-extreme Precipitation"))
# how many steps to match on
lag_num <- nrow(filter(clim_df, is_control == "Extreme Precipitation" & int==0) %>%
select(step) %>%
distinct())
cyclone_step <- lag_num+1
# do not conduct any matching, just compare extreme precip vs non-extreme precip units
unmatch_res <- PanelMatch(lag = lag_num, time.id = "step", unit.id = "place",
treatment = "int", refinement.method = "none",
data = clim_df, match.missing =FALSE,
size.match = match_num, qoi = "att",
use.diagonal.variance.matrix = TRUE,
covs.formula = ~ mean_temp + mean_rain,
outcome.var = "mean_rain")
# conduct matching for each of the extreme precip units
match_res <- PanelMatch(lag = lag_num, time.id = "step", unit.id = "place",
treatment = "int", refinement.method = "mahalanobis",
data = clim_df, match.missing =FALSE,
size.match = match_num, qoi = "att",
use.diagonal.variance.matrix = TRUE,
covs.formula = ~ mean_temp + mean_rain,
outcome.var = "mean_rain")
# calculate standardized differences
bal_calc <- get_covariate_balance(match_res$att, clim_df, c("mean_rain", "mean_temp"), plot=FALSE) %>% colMeans()
# absolute standardized differences
abs_bal_calc <- get_covariate_balance(match_res$att, clim_df, c("mean_rain", "mean_temp"), plot=FALSE) %>% abs() %>% colMeans()
# extract the names of matched units
matched_prov <- list()
# how many times was each matched unit selected (define weights to take weighted average)
for(i in 1:length(match_res$att)){
matched_prov[[i]] <- names(attr(match_res$att[[i]], "weights")[attr(match_res$att[[i]], "weights") != 0])
}
# add the weights to the dataframe for matched control units
match_df <- matched_prov %>%
unlist() %>%
as.numeric() %>%
data.frame(place = .) %>%
group_by(place) %>%
dplyr::summarize(weight=n()) %>%
right_join(clim_df) %>%
mutate(weight = ifelse(is.na(weight), 1, weight)) # if not in matched control, everything is weighted equally
# get names of the matched provinces
matched_names <- match_df %>% filter(place %in% unlist(matched_prov)) %>% select(id) %>% unlist() %>% unique()
# label which units are in the matched control
match_df %<>% mutate(is_control = ifelse(id %in% matched_names, "Matched Control", is_control))
# table comparing covariate means in extreme precip, non-extreme precip, and matched control
match_tab <-   match_df %>%
filter(is_control == "Matched Control") %>%
mutate(is_control = "Non-extreme Precipitation",
weight = 1) %>%
rbind(match_df) %>% # we need to also have the matched control units counted in the non-extreme precip pool
group_by(is_control) %>%
# weighted averages and standard deviations
dplyr::summarize(`Mean Temp.` = paste0(mean(mean_temp), " (", weighted.mean(mean_temp, weight), ")"),
`Mean Precip.` = paste0(mean(mean_rain), " (", weighted.mean(mean_rain, weight), ")"),
`Sd. Temp.` = paste0(sd(mean_temp), " (", sqrt(Hmisc::wtd.var(mean_temp, weight)), ")"),
`Sd. Precip.` = paste0(sd(mean_rain), " (", sqrt(Hmisc::wtd.var(mean_rain, weight)), ")"),
n = length(unique(id)))
# names of treated units
treated_names <- filter(match_df, is_control == "Extreme Precipitation") %>%
select(id) %>%
unlist() %>%
unique()
# values that the function will return
match_out <- list("table" = match_tab,
"match_names" = matched_names,
"df" = match_df,
"treated_names" = treated_names,
"match_obj" = match_res,
"balance" = bal_calc,
"abs_bal" = abs_bal_calc,
"match_list" = matched_prov,
"years" = years,
"year_ind" = year_ind,
"cyclone_step" = cyclone_step)
# balance plots if desired
if(plot_bal == TRUE){
balance_plot(match_out, cyclone_step, file_prefix, years, year_ind)
climts_plot(match_out, cyclone_step, file_prefix, years, year_ind)
}
# map plot if desired
if(plot_map == TRUE){
matchmap_plot(map, big_map, file_prefix, match_out,
cases_2023 = cases_2023, buffer_zone=buffer_ids, coastal_dist = coastal_dist)
}
return(match_out)
}
#### GENERALIZED SYNTHETIC CONTROL FUNCTION ####
# Conducts generalized synthetic control analysis and returns values, optional plots
#
# Inputs: case_df: a dataframe of case reports by week, year, and unit id
#         match_out: output of the match_fun function
#         pop_df: a dataframe of population sizes by id and year
#         file_prefix: prefix to save pdf image (if spatt_plot or att_plot is true)
#         att_plot: TRUE/FALSE, whether to attributable cases over time
#         spatt_plot: TRUE/FALSE, whether to plot map of attributable cases by unit
#         map: shapefile of spatial units at level used for analysis (if spatt_plot is true)
#         big_map: shapefile of spatial units at higher administrative division to indicate borders (if spatt_plot is true)
#         lf_num: specify the number of latent factors to use (bypasses cross-validation for optimal latent factor number)
#         r.max: the maximum number of latent factors to test out in cross-validation for number of latent factors
#         use_clim: TRUE/FALSE, whether to include climate covariates in the synthetic control model
#         use_r0: TRUE/FALSE, whether to use temperature-dependent R0 instead of mean temperature in synthetic control model
#         inc: TRUE/FALSE, whether to conduct analysis on incidence instead of absolute cases. Set to false at own risk, other functions not adapted for this output.
#         start_year: earliest year to include in analysis
#         exclude_year: vector of years to be excluded from analysis
#         end_week: last week in 2023 to include in analysis
#         log_cases: TRUE/FALSE, whether to conduct analysis on logged cases. Use at own risk, other functions not adapted for this output.
#                     log-scaling not recommended for fect, see
#         method: specifies type of inference to conduct in fect package. default to ife (resampling to bootstrap CI). could use gsynth (conformal prediction interval).
# Output: pdf figures in the figs folder if requested and a list with the following entries
#         gsynth_obj: a gsynth object from the fect package
#         att_nums: summary of attributable cases (from  function)
#         years: the years over which climate data is provided
#         year_ind: the indices for when a new year starts
#         cyclone_step: index when cyclone occurred
#         pop: full population size of the extreme precip districts
#         pop.weights: population weights for the extreme precip districts (in the order of gsynth_out$tr)
synth_fun <- function(case_df, match_out, pop_df, file_prefix,
att_plot = FALSE,
spatt_plot = FALSE, map = NULL,
big_map = NULL,
lf_num=NA, r.max=5, use_clim=TRUE,
use_r0 = FALSE,
inc=TRUE, start_year = 2010,
exclude_year = c(),
end_week = 52, log_cases=FALSE,
method="ife") {
# fail if requesting a map without providing shapefile
if(spatt_plot==TRUE & is.null(map)){
stop("Provide map to plot")
}
# treated and matched units
incl_units <- c(match_out$treated_names, match_out$match_names)
if(use_clim == TRUE){
# read in climate
df <- fread("clim_df.csv") %>%
# filter to treated and matched control regions
filter(id %in% incl_units) %>%
filter(date <= as_date("2023-12-31"))
# set up appropriate lags
df <- left_join(df %>%
select(-rain) %>%
mutate(date = date + 63),
df %>%
select(-c("temp", "rel_r0")) %>%
mutate(date = date + 42))
df %<>%
# convert to epiweek
mutate(week=epiweek(date), year=year(date), month=month(date))  %>%
# sometimes the last few days of a year get assigned to first epiweek of following year
mutate(year = ifelse(week == 1 & month == 12, year+1, year)) %>%
mutate(id = str_pad(id, 6, pad="0")) %>%
group_by(week, year, id) %>%
dplyr::summarize(mean_temp = mean(temp),
mean_rain = mean(rain),
mean_rel_r0 = mean(rel_r0)) %>%
left_join(case_df) %>%
filter(!is.na(mean_temp)) %>%
filter(id %in% incl_units) %>%
# filter to specified time period
filter(year >= start_year) %>%
filter(! year %in% exclude_year) %>%
filter(week <= end_week) %>%
filter(year <= 2023)
} else{
# still read in the climate covariates even though we won't use them to make sure the same districts are studied
# read in climate
df <- fread("clim_df.csv") %>%
# filter to treated and matched control regions
filter(id %in% incl_units) %>%
filter(date <= as_date("2023-12-31"))
# set up appropriate lags
df <- left_join(df %>%
select(-rain) %>%
mutate(date = date + 63),
df %>%
select(-c(temp, rel_r0)) %>%
mutate(date = date + 42))
df %<>%
# convert to epiweek
mutate(week=epiweek(date), year=year(date), month=month(date))  %>%
# sometimes the last few days of a year get assigned to first epiweek of following year
mutate(year = ifelse(week == 1 & month == 12, year+1, year)) %>%
mutate(id = str_pad(id, 6, pad="0")) %>%
group_by(week, year, id) %>%
dplyr::summarize(mean_temp = mean(temp),
mean_rain = mean(rain),
mean_rel_r0 = mean(rel_r0)) %>%
left_join(case_df) %>%
filter(!is.na(mean_temp)) %>%
# don't actually need the climate covariates
mutate(mean_temp = NA,
mean_rain = NA,
mean_rel_r0 = NA) %>%
filter(id %in% incl_units) %>%
filter(year >= start_year) %>%
filter(! year %in% exclude_year) %>%
filter(week <= end_week) %>%
filter(year <= 2023)
}
# we'll use this to group into 4-week periods
time_df <- df %>%
mutate(time = week+(year-min(case_df$year))*100) %>%
select(time, week, year) %>%
distinct() %>%
arrange(time) %>%
ungroup() %>%
mutate(weeknum = row_number()) %>%
mutate(step = ceiling(weeknum/4)) %>%
mutate(step = as.integer(step))
# will use this in plotting later
year_ind <- sapply(unique(time_df$year), function(x) min(which(time_df$year==x))/4)
years <- unique(time_df$year)
# aggregate to 4-epiweek periods, take average within those
df <- time_df %>%
right_join(df) %>%
group_by(id, step) %>%
dplyr::summarize(cases = sum(cases),
mean_temp = mean(mean_temp),
mean_rel_r0 = mean(mean_rel_r0),
mean_rain = mean(mean_rain)*1000,
year = max(year))
# when did the cyclone happen?
cyclone_step <- unique(time_df$step[time_df$week == 10 & time_df$year==2023])
# input a zero in weeks with missing data
df <- expand.grid(step=1:max(df$step, na.rm=TRUE), id=incl_units) %>%
left_join(df) %>%
left_join(pop_df) %>%
mutate(inc = cases/pop) %>%
mutate(cases = ifelse(is.na(cases), 0, cases),
inc = ifelse(is.na(inc) | is.infinite(inc), 0, inc)) %>%
mutate(int = ifelse(id %in% match_out$treated_names & step >= cyclone_step, 1, 0),
weight = 1) %>%
left_join(., match_out$df %>% select(id, is_control) %>% distinct() %>% filter(is_control %in% c("Extreme Precipitation", "Matched Control")))
tr_pop <- df %>% filter(int==1 & year==2023) %>% select(pop, id) %>% distinct() %>% filter(!is.na(pop)) %>% select(pop) %>% sum()
#  if specified, use incidence or logged cases as outcome
if(inc == TRUE){
df %<>% mutate(y = inc,
weight = pop)
}
else if(log_cases == TRUE){
df %<>% mutate(y = log(cases+exp(-1)))
}
else{
df %<>% mutate(y = cases)
}
# whether to use cross-validation period or pre-set the number of latent factors
if(is.na(lf_num)){
CV <- TRUE
r <- c(0,r.max)
}
else{
CV <- FALSE
r <- lf_num
}
# lets us get district-level estimates more easily
df$group <- df$id
# running the fect package to get the synthetic control results
if(use_clim == TRUE){
if(use_r0 == TRUE){
gsynth_out <- df %>%
fect(y ~ int + mean_rel_r0 + mean_rain, data = .,
index=c("id", "step"),
force = "two-way",
method=method,
se = TRUE,
CV = CV, r = r,
seed = 514,
nboots = 1000,
group="group",
W="weight")
# model without climate covariates
} else {
gsynth_out <- df %>%
fect(y ~ int + mean_temp + mean_rain, data = .,
index=c("id", "step"),
force = "two-way",
method=method,
se = TRUE,
CV = CV, r = r,
seed = 514,
nboots = 1000,
group="group",
W="weight")
}
} else {
gsynth_out <- df %>%
fect(y ~ int, data = .,
index=c("id", "step"),
force = "two-way",
method=method,
se = TRUE,
CV = CV, r = r,
seed = 514,
nboots=1000,
group="group",
W="weight")
}
print("ran")
# get population weights for bootstraps
if(inc == TRUE){
# which treated locations are included in each bootstrap?
boot.locs <- lapply(gsynth_out$boot.ids, function(n) gsynth_out$id[n[1:length(gsynth_out$tr)]])
# what are their population sizes
boot.pops <- lapply(boot.locs, function(boot) unlist(sapply(boot, function(loc) pop_df$pop[which(pop_df$id == loc & pop_df$year == 2023)])))
# population weights for each bootstrap
boot.weights <- lapply(boot.pops, function(each.pop) each.pop/sum(each.pop))
act.locs <- gsynth_out$id[gsynth_out$tr]
act.pops <- sapply(act.locs, function(loc) pop_df$pop[which(pop_df$id == loc & pop_df$year == 2023)])
act.weights <- unlist(act.pops)/tr_pop
}
else{
boot.weights <- lapply(1:length(gsynth_out$boot.ids), function(n) rep(1, length.out = length(gsynth_out$tr)))
}
# calculate percent attributable cases based on bootstraps
lapply(1:length(gsynth_out$Y.boot), function(n) apply(gsynth_out$Y.boot[[n]][,1:length(gsynth_out$tr)], 1, function(x) sum(x*boot.weights[[n]]))) %>%
do.call(cbind, .) %>%
`/`(gsynth_out$att.W.boot, .) %>% ## check this
ifelse(is.infinite(.), 0, .) %>% # set proportion to zero when no reported cases
apply(1, function(x) c(quantile(x, c(.025, .975)), sd(x)/sqrt(length(x)), sum(x<=0)/length(x))) %>% # recalculate 95% CI, standard error, p-value
t() %>%
data.frame() %>%
rename(lower.pct = 1,
upper.pct = 2,
recalc.SE = 3,
recalc.p = 4
) %>%
cbind(obs.inc = apply(gsynth_out$Y.dat[,gsynth_out$tr], 1, function(x) sum(x * act.weights))) %>%
mutate(obs.cases = obs.inc*tr_pop) %>%
mutate(lower.num = lower.pct*obs.inc,  #use reported cases and percent attributable to calculate number attributable
upper.num=upper.pct*obs.inc) %>%
cbind(gsynth_out$est.att.W) %>%
mutate(mid.pct = ATT/obs.inc,
mid.num=ATT,
mid.cases=ATT*tr_pop,
upper.cases=upper.num*tr_pop,
lower.cases=lower.num*tr_pop) -> gsynth_out$est.att
# calculate rsq
gsynth_out$rsq <- cor(c(gsynth_out$Y.dat[1:length(gsynth_out$pre.periods),gsynth_out$tr]),
c(gsynth_out$Y.ct[1:length(gsynth_out$pre.periods),gsynth_out$tr]))^2
# generate plots if requested
if(att_plot==TRUE){
att_plot(df, gsynth_out, cyclone_step, tr_pop, act.weights, file_prefix,
year_ind, unique(time_df$year), inc = inc)
}
if(spatt_plot==TRUE){
spatt_plot(gsynth_out,
map = map, big_map = big_map,
file_prefix=file_prefix)
}
# get attributable numbers
att_nums <- att_print(gsynth_out, df, cyclone_step,
boot.weights, tr_pop)
return(list("gsynth_obj"=gsynth_out,
"att_nums"=att_nums,
"year_ind"=year_ind,
"years"=years,
"cyclone_step"=cyclone_step,
"pop"=tr_pop,
"pop.weights"=act.weights))
}
synth_out_allper <- synth_fun(case_df, match_out_allper, pop_df, "adm3-allper",
att_plot=TRUE, spatt_plot=TRUE, map=per_map,
big_map=dept_map, use_clim=FALSE, use_r0=FALSE,
start_year = 2016, inc=TRUE)
head(df)
sum(!is.na(df$cases))
sum(df$cases,na.rm=TRUE)
remove.packages("fect")
install_github("mjharris95/fect") #on first run, use this to install modified fect package
install_github("mjharris95/fect") #on first run, use this to install modified fect package
install_github("mjharris95/fect") #on first run, use this to install modified fect package
library(fect)
synth_out_allper <- synth_fun(case_df, match_out_allper, pop_df, "adm3-allper",
att_plot=TRUE, spatt_plot=TRUE, map=per_map,
big_map=dept_map, use_clim=FALSE, use_r0=FALSE,
start_year = 2016, inc=TRUE)
